"""
Korean Heritage ì™„ì „ ì˜ì–´ ë²ˆì—­ ì‹œìŠ¤í…œ (Cursor/ë¡œì»¬ í™˜ê²½ìš©)
- Upstage Solar Pro2 API ì‚¬ìš©
- AMD Ryzen 9 5900X ìµœì í™” (8ì›Œì»¤)
- ì˜ˆìƒ ì†Œìš”ì‹œê°„: 4-6ì‹œê°„, ë¹„ìš©: $7-8
"""

import json, time, concurrent.futures, re, os
import requests
from openai import OpenAI
from datetime import datetime

print("ğŸ”¥ Korean Heritage ì™„ì „ ì˜ì–´ ë²ˆì—­ ì‹œì‘!")
print("ğŸ’» AMD Ryzen 9 5900X (12ì½”ì–´) ìµœì í™”")

# ===== ì„¤ì • =====
UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")
if not UPSTAGE_API_KEY:
    print("âŒ UPSTAGE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    print("í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”:")
    print("Windows: $env:UPSTAGE_API_KEY=\"ì—¬ê¸°ì—_API_í‚¤_ì…ë ¥\"")
    print("Linux/macOS: export UPSTAGE_API_KEY=\"ì—¬ê¸°ì—_API_í‚¤_ì…ë ¥\"")
    exit(1)

MAX_WORKERS = 8  # 12ì½”ì–´ CPU ìµœì í™”
BACKUP_INTERVAL = 100  # 100ê°œë§ˆë‹¤ ë°±ì—…

# ===== OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ì‚¬ì¥ë‹˜ ê²€ì¦ëœ ë°©ì‹) =====
client = OpenAI(
    api_key=UPSTAGE_API_KEY,
    base_url="https://api.upstage.ai/v1/solar"
)

# ===== API ì—°ê²° í…ŒìŠ¤íŠ¸ =====
def test_connection():
    try:
        response = client.chat.completions.create(
            model="solar-pro2",
            messages=[{"role": "user", "content": "ì—°ê²° í…ŒìŠ¤íŠ¸"}],
            max_tokens=5
        )
        print("âœ… Upstage Solar Pro2 API ì—°ê²° ì„±ê³µ!")
        return True
    except Exception as e:
        print(f"âŒ API ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

if not test_connection():
    exit(1)

# ===== ë°ì´í„° ë¡œë“œ =====
def load_heritage_data():
    print("ğŸ“¥ GitHubì—ì„œ heritage-data.js ë¡œë“œ ì¤‘...")
    url = "https://raw.githubusercontent.com/yuyongkim/Korean_Heritage/main/js/heritage-data.js"
    
    response = requests.get(url, timeout=30)
    response.raise_for_status()
    
    js_content = response.text
    match = re.search(r'HERITAGE_DATA\s*=\s*(\[[\s\S]*?\]);', js_content)
    if not match:
        raise ValueError("HERITAGE_DATA ë°°ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    array_text = match.group(1).replace('NaN', 'null')
    heritage_data = json.loads(array_text)
    
    print(f"âœ… ì „ì²´ ë¬¸í™”ì¬ ë¡œë“œ: {len(heritage_data):,}ê°œ")
    return heritage_data

heritage_data = load_heritage_data()

# ===== ë¯¸ë²ˆì—­ í•­ëª© í•„í„°ë§ =====
untranslated_items = [
    item for item in heritage_data 
    if not (item.get('name_en') and item.get('content_en'))
]

if not untranslated_items:
    print("ğŸ‰ ëª¨ë“  ë¬¸í™”ì¬ê°€ ì´ë¯¸ ë²ˆì—­ë˜ì—ˆìŠµë‹ˆë‹¤!")
    exit(0)

print(f"ğŸ¯ ë²ˆì—­ ëŒ€ìƒ: {len(untranslated_items):,}ê°œ")

# ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
category_count = {}
for item in untranslated_items:
    cat = item.get('kdcd_name', 'ê¸°íƒ€')
    category_count[cat] = category_count.get(cat, 0) + 1

print("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
for cat, count in sorted(category_count.items(), key=lambda x: x[1], reverse=True)[:10]:
    print(f"  - {cat}: {count:,}ê°œ")

# ì˜ˆìƒ ë¹„ìš©/ì‹œê°„
estimated_tokens = len(untranslated_items) * 1500
estimated_cost = estimated_tokens / 1_000_000 * 0.30
estimated_hours = len(untranslated_items) / MAX_WORKERS * 6 / 3600

print(f"\nğŸ’° ì˜ˆìƒ ë¹„ìš©: ${estimated_cost:.2f}")
print(f"â° ì˜ˆìƒ ì‹œê°„: {estimated_hours:.1f}ì‹œê°„")

# ===== ë²ˆì—­ í•¨ìˆ˜ =====
def translate_item(item, max_retries=3):
    name = item.get('name', '')
    content = item.get('content', '')
    key_asno = item.get('key_asno')
    
    delay = 2.0
    for attempt in range(1, max_retries + 1):
        try:
            response = client.chat.completions.create(
                model="solar-pro2",
                messages=[
                    {
                        "role": "system", 
                        "content": "í•œêµ­ ë¬¸í™”ì¬ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
                    },
                    {
                        "role": "user", 
                        "content": f"ë¬¸í™”ì¬ëª…: {name}\nìƒì„¸ì„¤ëª…: {content}\n\nJSON: {{\"name_en\": \"ì˜ë¬¸ëª…\", \"content_en\": \"ì˜ë¬¸ì„¤ëª…\"}}"
                    }
                ],
                temperature=0.2,
                max_tokens=4000,
                extra_body={
                    "reasoning_effort": "high"
                }
            )
            
            content_text = response.choices[0].message.content.strip()
            
            # JSON ì¶”ì¶œ
            if '```json' in content_text:
                content_text = content_text.split('```json')[1].split('```')[0].strip()
            elif '```' in content_text:
                content_text = content_text.split('```')[1].split('```')[0].strip()
            
            try:
                parsed = json.loads(content_text)
                return {
                    "success": True,
                    "key_asno": key_asno,
                    "name_en": parsed.get("name_en", name),
                    "content_en": parsed.get("content_en", content),
                    "tokens": response.usage.total_tokens if response.usage else 0
                }
            except json.JSONDecodeError:
                if attempt < max_retries:
                    time.sleep(delay)
                    delay *= 1.5
                    continue
                else:
                    # JSON íŒŒì‹± ì‹¤íŒ¨í•´ë„ ë²ˆì—­ í…ìŠ¤íŠ¸ëŠ” ì €ì¥
                    return {
                        "success": True,
                        "key_asno": key_asno,
                        "name_en": name,
                        "content_en": content_text,
                        "tokens": response.usage.total_tokens if response.usage else 0
                    }
        except Exception as e:
            if attempt < max_retries:
                time.sleep(delay)
                delay *= 1.5
                continue
    
    return {"success": False, "key_asno": key_asno, "error": "ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼"}

# ===== ë°°ì¹˜ ë²ˆì—­ =====
def translate_batch(items):
    results = []
    failed_items = []
    total_tokens = 0
    start_time = time.time()
    
    print(f"ğŸš€ {len(items):,}ê°œ ë¬¸í™”ì¬ ë²ˆì—­ ì‹œì‘ ({MAX_WORKERS}ì›Œì»¤)")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_item = {executor.submit(translate_item, item): item for item in items}
        
        for i, future in enumerate(concurrent.futures.as_completed(future_to_item), 1):
            result = future.result()
            item_name = future_to_item[future]['name']
            
            if result and result.get("success"):
                results.append(result)
                tokens = result.get("tokens", 0)
                total_tokens += tokens
                cost = total_tokens / 1_000_000 * 0.30
                
                print(f"  âœ… {i:4d}/{len(items):,}: {item_name[:40]}...")
                
                # 50ê°œë§ˆë‹¤ ì§„í–‰ìƒí™© í‘œì‹œ
                if i % 50 == 0:
                    elapsed = time.time() - start_time
                    eta = elapsed / i * (len(items) - i)
                    success_rate = len(results) / i * 100
                    speed = i / elapsed * 3600  # ê°œ/ì‹œê°„
                    
                    print(f"ğŸ“Š ì§„í–‰ë¥ : {i:,}/{len(items):,} ({i/len(items)*100:.1f}%)")
                    print(f"   ì„±ê³µë¥ : {success_rate:.1f}% | ì†ë„: {speed:.0f}ê°œ/ì‹œê°„")
                    print(f"   ê²½ê³¼: {elapsed/3600:.1f}h | ETA: {eta/3600:.1f}h | ë¹„ìš©: ${cost:.2f}")
            else:
                failed_items.append(result)
                print(f"  âŒ {i:4d}/{len(items):,}: {item_name[:40]}...")
            
            # ë°±ì—… ì €ì¥
            if len(results) % BACKUP_INTERVAL == 0 and len(results) > 0:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_file = f"backup_{len(results)}_{timestamp}.json"
                
                backup_data = {
                    "timestamp": timestamp,
                    "completed": len(results),
                    "total": len(items),
                    "results": results
                }
                
                with open(backup_file, 'w', encoding='utf-8') as f:
                    json.dump(backup_data, f, ensure_ascii=False, indent=2)
                
                print(f"ğŸ’¾ ë°±ì—… ì €ì¥: {backup_file}")
    
    elapsed = time.time() - start_time
    final_cost = total_tokens / 1_000_000 * 0.30
    
    print(f"\nğŸ‰ ë²ˆì—­ ì™„ë£Œ!")
    print(f"âœ… ì„±ê³µ: {len(results):,}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {len(failed_items):,}ê°œ") 
    print(f"ğŸ“Š ì„±ê³µë¥ : {len(results)/(len(results)+len(failed_items))*100:.1f}%")
    print(f"â° ì´ ì‹œê°„: {elapsed/3600:.1f}ì‹œê°„")
    print(f"ğŸ’° ì´ ë¹„ìš©: ${final_cost:.2f}")
    print(f"ğŸš€ í‰ê·  ì†ë„: {len(results)/elapsed*3600:.0f}ê°œ/ì‹œê°„")
    
    return results, failed_items

# ===== ì‹¤í–‰ í™•ì¸ =====
print(f"\nğŸš€ {len(untranslated_items):,}ê°œ ë¬¸í™”ì¬ ë²ˆì—­ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
response = input("ê³„ì†í•˜ë ¤ë©´ 'y'ë¥¼ ì…ë ¥í•˜ì„¸ìš” (y/N): ")

if response.lower() != 'y':
    print("âŒ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    exit(0)

# ===== ë²ˆì—­ ì‹¤í–‰ =====
translation_results, failed_items = translate_batch(untranslated_items)

# ===== ë°ì´í„° ë³‘í•© =====
print("\nğŸ”„ ë²ˆì—­ ê²°ê³¼ë¥¼ ì›ë³¸ ë°ì´í„°ì— ë³‘í•© ì¤‘...")

translation_dict = {r["key_asno"]: r for r in translation_results if r.get("success")}

updated_count = 0
for item in heritage_data:
    key_asno = item.get("key_asno")
    if key_asno in translation_dict:
        trans = translation_dict[key_asno]
        item["name_en"] = trans["name_en"]
        item["content_en"] = trans["content_en"]
        updated_count += 1

print(f"âœ… {updated_count:,}ê°œ ë¬¸í™”ì¬ì— ì˜ì–´ ë²ˆì—­ ì¶”ê°€ ì™„ë£Œ")

# ===== ìµœì¢… íŒŒì¼ ìƒì„± =====
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
output_file = f"heritage-data-complete-{timestamp}.js"

js_content = f"const HERITAGE_DATA = {json.dumps(heritage_data, ensure_ascii=False, indent=2)};"

with open(output_file, "w", encoding="utf-8") as f:
    f.write(js_content)

print(f"ğŸ“ ìµœì¢… íŒŒì¼ ìƒì„±: {output_file}")

# ===== í’ˆì§ˆ ê²€ì¦ =====
translated_items = [item for item in heritage_data if item.get('name_en') and item.get('content_en')]

print(f"\nğŸ” ìµœì¢… ê²€ì¦: {len(translated_items):,}ê°œ ë¬¸í™”ì¬ ë²ˆì—­ ì™„ë£Œ")

# ìƒ˜í”Œ 3ê°œ ì¶œë ¥
import random
samples = random.sample(translated_items, min(3, len(translated_items)))

print("\nğŸ“‹ ë²ˆì—­ í’ˆì§ˆ ìƒ˜í”Œ:")
for i, item in enumerate(samples, 1):
    print(f"\n=== ìƒ˜í”Œ {i} ===")
    print(f"ì¹´í…Œê³ ë¦¬: {item.get('kdcd_name', 'N/A')}")
    print(f"í•œê¸€ëª…: {item['name']}")
    print(f"ì˜ì–´ëª…: {item['name_en']}")
    print(f"í•œê¸€ì„¤ëª…: {item['content'][:80]}...")
    print(f"ì˜ì–´ì„¤ëª…: {item['content_en'][:80]}...")

print(f"\nğŸ¯ ì „ì²´ ì‘ì—… ì™„ë£Œ!")
print(f"ğŸ“Š ìµœì¢… ê²°ê³¼: {len(translation_results):,}ê°œ ë²ˆì—­ ì™„ë£Œ")
print(f"ğŸ“ GitHubì— {output_file} ì—…ë¡œë“œí•˜ì—¬ í™ˆí˜ì´ì§€ ì—°ë™ ì™„ì„±í•˜ì„¸ìš”")

print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
print(f"1. {output_file}ì„ heritage-data.jsë¡œ ì´ë¦„ ë³€ê²½")
print(f"2. GitHubì— ì—…ë¡œë“œ")
print(f"3. í™ˆí˜ì´ì§€ì—ì„œ í•œê¸€/English í† ê¸€ í…ŒìŠ¤íŠ¸")
